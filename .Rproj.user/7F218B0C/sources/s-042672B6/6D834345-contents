---
title: "CTS_project"
author: "Cheng Hua"
date: "5/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Teacher Commitment Scale

## Part 1 EFA Analysis

### Load the dataset

```{r}
library(haven)
TCS <- read_sav("Desktop/Current Work/Dr. Sun's Project/Teacher Commitment Scale/Teacher Commitment Scale.sav")
```

### Decriptive Data Analysis

```{r}
library(psych)
TCS_data <- TCS[,1:12]
summary(TCS_data) # TC3 Minimum Mean = 3.48; 
table(TCS$Gender) # 1: male; 2:female
table(TCS$YTeach) # 1: "1-2 years"; 2: "3-5 years"; 3:"6-10 years"; 4:"11 years+"
table(TCS$HstDgreee) # 1: Bachelor; 2: Master; 3: Doctoral; 4: Other
```

### Exploratory Factor Analysis (EFA)
```{r}
library("Hmisc")
## Check the correlation matrix
cor(TCS_data, method = "pearson", use = "complete.obs")
## Now we reverse code the TC3
library(car)
reversed_TC3 <- recode(TCS_data$TC3,"1=6;2=5;3=4;4=3;5=2;6=1") 
recoded_TCS_data <- TCS_data
recoded_TCS_data$TC3 <- reversed_TC3
## Check the correlation matrix
cor(recoded_TCS_data, method = "pearson", use = "complete.obs")
library(ltm)
cronbach.alpha(recoded_TCS_data) # Report Internal Consistency (reliability)
# Principal Components Analysis
# Run a PCA to determine the number of factors
fit <- princomp(recoded_TCS_data, cor=TRUE)
summary(fit) # print variance accounted for
loadings(fit) # pc loadings
plot(fit,type="lines") # scree plot
# From the plot we can see there are 4 primary factors contributing to the total variance
# Varimax Rotated Principal Components
scale_fa <- factanal(recoded_TCS_data,factors=4,rotation="varimax")
scale_fa # Check the factor loadings in here.
```

According to the factor loading, we can conclude that:
D1: TC1, TC2 or (TC12)
D2: TC8, TC9, TC10 or (TC12)
D3: TC3(weak), TC4, TC5, TC6, TC7
D4: TC11 or (TC12)

### One-level CFA

```{r}
# Load the R packages that needed for the analysis
library(foreign) 
library(lavaan)
# Establish our model
model <-'TC=~Student_Learning+Change+School+Teaching_profession
Student_Learning=~TC1+TC2+TC12
Change=~TC8+TC9+TC10
School=~TC3+TC4+TC5+TC6+TC7
Teaching_profession=~TC11'
# Factor 1 = Commitment to Student_Learning
# Factor 2 = Commitment to Change
# Factor 3 = Commitment to School
# Factor 4 = Commitment to Teaching_profession
# Fit the CFA model
# test_data <- recoded_TCS_data[,c(-3,-7)]
fit_cfa <- cfa(model, data=recoded_TCS_data)
# Check the model summary
summary(fit_cfa,fit.measure=TRUE)
# Print out the paramarter Estimates
parameterEstimates(fit_cfa)
modificationindices(fit_cfa)
library("lavaanPlot")
lavaanPlot(model=fit_cfa,node_options=list(shape="box",fontname="Helvetica"),edge_options=list(color="blue"),coefs=TRUE, covs=TRUE, stars=c("regress"),stand = FALSE)
```

Based on the results, we do not use the CFA's result due to the small sample size.

## Part 2 Rasch Analysis

### Prepare the package
```{r}
## Running the Rasch Rating Scale Model
library(TAM) # For running the Rating Scale Rasch Model
library(plyr) # For plot the Item characteristic curves
library(WrightMap)# For plot the variable map
library(eRm) # For another example
```

### Run the Partial Credit Model
```{r}
# Run the Partial Credit Model
recoded_TCS_data1 <- recoded_TCS_data[-7,]
PC_model <- PCM(recoded_TCS_data1)
# Check the result
summary(PC_model)
# Plot the Variable Map
plotPImap(PC_model)

### Examine item difficulty values:
item.estimates <- thresholds(PC_model)
item.estimates

## Get threshold SEs values:
item.se <- item.estimates$se.thresh
item.se

# Standard errors for theta estimates:
person.locations.estimate <- person.parameter(PC_model)
summary(person.locations.estimate)

# Build a table for person locations
person_theta <- person.locations.estimate$theta.table
person_theta
item.fit <- itemfit(person.locations.estimate)
item.fit
item.fit.table <- cbind(item.fit[["i.outfitMSQ"]],item.fit[["i.infitMSQ"]],item.fit[["i.infitMSQ"]],item.fit[["i.infitZ"]])
pfit <- personfit(person.locations.estimate)
pfit
person.fit.table <- cbind(pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]])

# ===================================
# compute item separation reliability
# ===================================

# Get Item scores
ItemScores <- colSums(recoded_TCS_data)

# Get Item SD
ItemSD <- apply(recoded_TCS_data,2,sd)

# Calculate the se of the Item
ItemSE <- ItemSD/sqrt(length(ItemSD))

# compute the Observed Variance (also known as Total Person Variability or Squared Standard Deviation)
SSD.ItemScores <- var(ItemScores)

# compute the Mean Square Measurement error (also known as Model Error variance)
Item.MSE <- sum((ItemSE)^2) / length(ItemSE)

# compute the Item Separation Reliability
item.separation.reliability <- (SSD.ItemScores-Item.MSE) / SSD.ItemScores
item.separation.reliability

# ===================================
# compute person separation reliability
# ===================================

# Get Person scores
PersonScores <- rowSums(recoded_TCS_data)

# Get Person SD
PersonSD <- apply(recoded_TCS_data,1,sd)

# Calculate the se of the Person
PersonSE <- PersonSD/sqrt(length(PersonSD))

# compute the Observed Variance (also known as Total Person Variability or Squared Standard Deviation)
SSD.PersonScores <- var(PersonScores)

# compute the Mean Square Measurement error (also known as Model Error variance)
Person.MSE <- sum((PersonSE)^2) / length(PersonSE)

# compute the Person Separation Reliability
person.separation.reliability <- (SSD.PersonScores-Person.MSE) / SSD.PersonScores
person.separation.reliability
```



